{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Demo\n",
    "This notebook is intended to be used with a [SageMaker notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html) launched using the following [CloudFormation](https://docs.aws.amazon.com/cloudformation/) template:\n",
    "\n",
    "- [sagemaker-notebook-cloudformation.yml](https://github.com/managedkaos/jupyter-environment-details/blob/main/sagemaker-notebook-cloudformation.yml)\n",
    "\n",
    "Together the CloudFormation template and this notebook demonstrate:\n",
    "\n",
    "- Attaching an IAM role to a SageMaker instance with policies that allow the instance to use other AWS services\n",
    "- Using the [Boto3 Python library](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) to create clients for accessing AWS services\n",
    "- Using boto3 clients to read from [Parameter Store](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html) and write to an [S3 bucket](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab some metadata from the local system's `/opt/ml/metadata/resource-metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "file_path = \"/opt/ml/metadata/resource-metadata.json\"\n",
    "\n",
    "# Open the file and load its content\n",
    "with open(file_path, \"r\") as file:\n",
    "    metadata = json.load(file)\n",
    "\n",
    "# Access the ResourceName value\n",
    "notebook_instance_name = metadata[\"ResourceName\"]\n",
    "\n",
    "print(\"\\tNotebook instance name:\", notebook_instance_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Boto3 library and initialize clients for S3 and SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --quiet boto3 pandas plotly scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "ssm_client = boto3.client(\"ssm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions\n",
    "- read_from_parameter_store(name)\n",
    "- write_to_s3(bucket, key, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read value from Parameter Store\n",
    "def read_from_parameter_store(name):\n",
    "    response = ssm_client.get_parameter(Name=name, WithDecryption=True)\n",
    "    return response[\"Parameter\"][\"Value\"]\n",
    "\n",
    "\n",
    "# Write data to the S3 bucket\n",
    "def write_to_s3(bucket, key, body):\n",
    "    s3_client.put_object(Bucket=bucket, Key=key, Body=body)\n",
    "    print(f\"\\tSuccessfully wrote data to s3://{bucket}/{key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from SSM ParameterStore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the S3 bucket name and region from Parameter Store\n",
    "bucket_name = read_from_parameter_store(f\"/{notebook_instance_name}/s3bucket\")\n",
    "region_name = read_from_parameter_store(f\"/{notebook_instance_name}/region\")\n",
    "\n",
    "print(f\"\\tS3 Bucket Name from Parameter Store: {bucket_name}\")\n",
    "print(f\"\\tRegion Name from Parameter Store: {region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do something really cool in the following cell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\tHello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data: calculating Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal, getcontext\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pi_archimedes(n):\n",
    "    # Calculate pi over n iterations using the approach from Archimedes\n",
    "    polygon_edge_length_squared = Decimal(2)\n",
    "    polygon_sides = 2\n",
    "    for i in range(n):\n",
    "        polygon_edge_length_squared = (\n",
    "            2 - 2 * (1 - polygon_edge_length_squared / 4).sqrt()\n",
    "        )\n",
    "        polygon_sides *= 2\n",
    "    return polygon_sides * polygon_edge_length_squared.sqrt()\n",
    "\n",
    "\n",
    "data = []\n",
    "places = 100\n",
    "old_result = None\n",
    "\n",
    "for n in range(10 * places):\n",
    "    getcontext().prec = 2 * places  # Do calculations with double precision\n",
    "    result = pi_archimedes(n)\n",
    "    getcontext().prec = places  # Print the result with single precision\n",
    "    result = +result  # Rounding\n",
    "    data.append(result)\n",
    "    if result == old_result:  # Did it converge?\n",
    "        break\n",
    "    old_result = result\n",
    "\n",
    "df = pd.DataFrame({\"Iteration\": list(range(len(data))), \"Pi\": data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_directory = \"./data\"\n",
    "\n",
    "os.makedirs(data_directory, exist_ok=True)\n",
    "chunk_size = 25  # Number of rows per chunk\n",
    "\n",
    "# Iterate through the DataFrame in chunks and write each to a separate HTML file\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_df = df.iloc[i : i + chunk_size]\n",
    "    filename = f\"{data_directory}/data-{i//chunk_size + 1}.html\"\n",
    "    chunk_df.to_html(filename, index=False)\n",
    "    print(f\"\\tWrote data {i} to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pickle the Pi dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = f\"{data_directory}/pi-data.pkl\"\n",
    "\n",
    "# Open a file in binary write mode ('wb')\n",
    "with open(pickle_file, \"wb\") as f:\n",
    "    # Use pickle.dump() to serialize and save the object to the file\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "print(f\"\\tPi data serialized to {pickle_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import plotly.express as px\n",
    "\n",
    "# Generate synthetic data with 3D features\n",
    "x, y = make_blobs(n_samples=200, centers=7, n_features=3, random_state=42)\n",
    "\n",
    "# Convert the data to a format suitable for Plotly Express\n",
    "df3 = pd.DataFrame(np.column_stack((x, y)), columns=[\"X\", \"Y\", \"Z\", \"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters in 2D\n",
    "fig3 = px.scatter(df3, x=\"X\", y=\"Y\", color=\"Cluster\", title=\"2D Cluster Visualization\")\n",
    "\n",
    "# Write the figure to disk\n",
    "fig3.write_html(f\"{data_directory}/graph-cluster-2d-visualization.html\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters in 3D\n",
    "fig3 = px.scatter_3d(\n",
    "    df3, x=\"X\", y=\"Y\", z=\"Z\", color=\"Cluster\", title=\"3D Cluster Visualization\"\n",
    ")\n",
    "\n",
    "# Write the figure to disk\n",
    "fig3.write_html(f\"{data_directory}/graph-cluster-3d-visualization.html\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3 and create `index.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import subprocess\n",
    "\n",
    "website = f\"http://{bucket_name}.s3-website-{region_name}.amazonaws.com\"\n",
    "\n",
    "# Use the fnmatch module to find all files in the current directory that end in \".html\"\n",
    "file_list = []\n",
    "for root, dirnames, filenames in os.walk(\".\"):\n",
    "    for filename in fnmatch.filter(filenames, \"*.html\"):\n",
    "        file_list.append(os.path.join(root, filename))\n",
    "\n",
    "# Sort the file list alphabetically\n",
    "file_list.sort()\n",
    "\n",
    "# Create the HTML file and write the header\n",
    "with open(os.path.join(\".\", \"index.html\"), \"w\") as f:\n",
    "    f.write(\n",
    "        \"\"\"<html>\n",
    "        <head>\n",
    "            <title>HTML Output</title>\n",
    "            <style>\n",
    "                table {\n",
    "                    border-collapse: collapse;\n",
    "                    width: 100%;\n",
    "                }\n",
    "                th, td {\n",
    "                    text-align: left;\n",
    "                    padding: 8px;\n",
    "                }\n",
    "                th {\n",
    "                    background-color: #007bff;\n",
    "                    color: #fff;\n",
    "                    font-weight: bold;\n",
    "                }\n",
    "                tr:nth-child(even) {\n",
    "                    background-color: #f2f2f2;\n",
    "                }\n",
    "                tr:hover {\n",
    "                    background-color: #ddd;\n",
    "                }\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <table>\n",
    "                <tr><th>Name</th><th>Size</th></tr>\\n\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    # Loop through each file and add a row to the table\n",
    "    for file_name in file_list:\n",
    "        if file_name in [\"./index.html\"]:\n",
    "            continue\n",
    "\n",
    "        file_size = os.path.getsize(file_name)\n",
    "        f.write(\n",
    "            f'<tr><td><a href=\"{website}/{file_name}\" target=\"_blank\" rel=\"noopener noreferrer\">{file_name}</a></td><td>{int(file_size / 1048576)} MB</td></tr>\\n'\n",
    "        )\n",
    "\n",
    "    # Write the footer and close the file\n",
    "    f.write(\"</table></body></html>\")\n",
    "    f.close()\n",
    "\n",
    "command = [\n",
    "    \"aws\",\n",
    "    \"s3\",\n",
    "    \"sync\",\n",
    "    \".\",\n",
    "    f\"s3://{bucket_name}\",\n",
    "    \"--exclude\",\n",
    "    \"*\",\n",
    "    \"--include\",\n",
    "    \"*.html\",\n",
    "    \"--include\",\n",
    "    \"*.pkl\",\n",
    "    \"--no-progress\",\n",
    "]\n",
    "\n",
    "# Run the command and wait for it to complete\n",
    "output = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output\n",
    "print(output.stdout)\n",
    "print(\"\\tfin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read the bucket contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objects = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "print(f\"\\tContents of bucket {bucket_name}:\")\n",
    "for obj in objects[\"Contents\"]:\n",
    "    print(f\"\\t\\t{obj['Key']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the pickled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved TfidfVectorizer\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "markdown_text = f\"\"\"\n",
    "## Access the data in the S3 bucket website\n",
    "Use the following link to view the data in the S3 bucket's website:\n",
    "\n",
    "## {website}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(markdown_text))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPtZFtImanTt3no3VZVCx1B",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
